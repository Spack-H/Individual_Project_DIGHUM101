# Individual_Project_DIGHUM101
# Human vs AI Text Classification Model

## Introduction

The rapid advancement of Artificial Intelligence (AI) technologies, particularly in natural language processing, has led to the creation of sophisticated models like Chat Generative Pre-trained Transformer (ChatGPT). These models generate text that closely resembles human-written content and are used extensively for various applications. While these advancements offer numerous opportunities for enhancing productivity and efficiency, they also pose significant challenges in identifying the true origin of the text.

## Research Question

The objective of this project is to analyze the performance of a computational model capable of distinguishing between human-written and AI-generated text. The model examines key linguistic and stylistic features to identify the unique aspects of human writing. Such a model seeks to enhance transparency and trust in communications by ensuring the authenticity of content. This project aims to address the research question: Can a computational model detect differences between human-written and AI-generated content?

## Dataset

The dataset used in this project is sourced from Kaggle: [AI vs Human Text Data](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text/data).

## Project Structure

- **Data Upload and Setup**: Uploading and setting up the dataset.
- **Data Reduction & Visualization**: Reducing the dataset size for faster computation and visualizing class distribution.
- **Text Examples**: Examples of both human and AI-generated text.
- **Text Preprocessing & Splitting**: Processing part of the text and splitting it into training and testing sets.
- **Vectorization**: Converting text data into numerical vectors using TF-IDF.
- **Model Training and Evaluation**: Training and evaluating Logistic Regression and Decision Tree models.
- **Results Visualization**: Visualizing confusion matrices for both models.
- **Model Performance Interpretation**: Interpreting the performance of the models.
- **Conclusion**: Summarizing the findings of the project.

## Results

The results indicate that the Logistic Regression model significantly outperforms the Decision Tree model in classifying text as either human or AI-generated. Logistic Regression achieved an accuracy of 97.22% on raw text and 96.70% on processed text, with F1 scores of 97.20% and 96.66%, respectively. In contrast, the Decision Tree model had an accuracy of 86.38% on raw text and 82.85% on processed text, with F1 scores of 85.86% and 82.37%. These findings suggest that raw text features are more informative for both models, and text preprocessing does not necessarily enhance model performance.

## Acknowledgments

The project was inspired by Amrutha K blog [How to Build a Machine Learning Model to Distinguish If Itâ€™s Human or ChatGPT?](https://www.analyticsvidhya.com/blog/2023/04/how-to-build-a-machine-learning-model-to-distinguish-if-its-human-or-chatgpt/).
